# Evaluation Framework

The `evaluation_framework/` directory defines how AIC-Research **evaluates an intelligent system**

when traditional measures like accuracy, benchmark scores, or leaderboards

no longer reflect the true risk.

AIC doesn't ask:

> “How strong is this system?”

AIC asks:

> “Is this system still reliable when things start to go wrong?”

Assessment in AIC focuses on:
- Long-term behavior
- Self-explanatory ability
- Ability to be controlled and reversed by humans
- How the system fails

A system is only considered successful

when **it fails in a way that is acceptable to humans**.